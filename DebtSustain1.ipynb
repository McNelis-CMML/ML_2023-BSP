{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789650c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   country_id      country  year  default_ext  default_ext2    rgdpgr  \\\n",
      "0           1  Philippines  1995            0             0  4.625225   \n",
      "1           1  Philippines  1996            0             0  5.860348   \n",
      "2           1  Philippines  1997            0             0  5.186412   \n",
      "3           1  Philippines  1998            0             0 -0.514091   \n",
      "4           1  Philippines  1999            0             0  3.346451   \n",
      "\n",
      "   debt_ppgdebt  debt_dsbxgsi  debt_dsbgni  debt_dsbexp  ...  bop_cabgdp  \\\n",
      "0     72.438503     16.321244     7.015681    14.335826  ...   -2.341154   \n",
      "1     61.525559     13.580253     6.235743    11.043362  ...   -4.176875   \n",
      "2     52.054704      9.475806     5.233374     7.323985  ...   -4.600133   \n",
      "3     54.418767     10.922605     5.740305     8.562020  ...    2.073440   \n",
      "4     59.456455     22.437779     6.248303    16.672487  ...   -3.360311   \n",
      "\n",
      "     kaopen  res_bopimp     er_app  inflation  gg_nlbgdp  gg_balgdp  \\\n",
      "0  1.055967   23.368701   2.454065   6.846861     -0.016     -0.016   \n",
      "1 -0.014185   28.497289  -2.003963   8.335624      0.537      0.537   \n",
      "2 -0.014185   17.432613 -11.518533   5.651232      0.367      0.367   \n",
      "3 -0.014185   27.356211 -27.343684   9.345158     -1.309     -1.309   \n",
      "4 -0.014185   48.319188   4.246442   6.214191     -2.288     -2.287   \n",
      "\n",
      "   mon_msres   mon_msgr  mon_msgdp  \n",
      "0   4.939016  23.874140  51.848185  \n",
      "1   3.960780  23.731508  56.296497  \n",
      "2   5.840642  23.107655  62.027870  \n",
      "3   3.687471   8.566311  55.344860  \n",
      "4   3.242766  16.882185  58.877154  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "df = pd.read_excel('data_debtsustain1.xlsx')\n",
    "print(df.head())  # This will display the first few rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a039d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['country_id', 'country', 'year', 'default_ext', 'default_ext2',\n",
      "       'rgdpgr', 'debt_ppgdebt', 'debt_dsbxgsi', 'debt_dsbgni', 'debt_dsbexp',\n",
      "       'debt_debtgni', 'debt_stdebtrat', 'debt_stres', 'debt_stxgsi',\n",
      "       'bop_cabgdp', 'kaopen', 'res_bopimp', 'er_app', 'inflation',\n",
      "       'gg_nlbgdp', 'gg_balgdp', 'mon_msres', 'mon_msgr', 'mon_msgdp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb1a026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(363, 21)\n",
      "(363,)\n",
      "Index(['country_id', 'year', 'rgdpgr', 'debt_ppgdebt', 'debt_dsbxgsi',\n",
      "       'debt_dsbgni', 'debt_dsbexp', 'debt_debtgni', 'debt_stdebtrat',\n",
      "       'debt_stres', 'debt_stxgsi', 'bop_cabgdp', 'kaopen', 'res_bopimp',\n",
      "       'er_app', 'inflation', 'gg_nlbgdp', 'gg_balgdp', 'mon_msres',\n",
      "       'mon_msgr', 'mon_msgdp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X1 = df.drop(['country','default_ext','default_ext2'], axis=1)\n",
    "y = df['default_ext']\n",
    "print(X1.shape)\n",
    "print(y.shape)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create an imputer that replaces missing values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit and transform the imputer on your feature data\n",
    "XX = imputer.fit_transform(X1)\n",
    "\n",
    "#X = (XX-np.min(XX)/np.max(XX)-np.min(XX))\n",
    "X = (XX-np.mean(XX)/np.std(XX))\n",
    "\n",
    "\n",
    "print(X1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6b225ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30303030303030304\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y)/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce270ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load your dataset\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# Drop unnecessary columns (e.g., 'country_id', 'country') or encode them if needed\n",
    "# Handle missing data if any\n",
    "\n",
    "# Split data into features and target variable (assuming 'default_ext' is your target)\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training and Evaluation\n",
    "\n",
    "# Random Forest Classifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='auto',\n",
    "    criterion='gini',\n",
    "    bootstrap=True,\n",
    "    class_weight=None  # You can specify class weights if needed\n",
    ")\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "rf_pred = rf_classifier.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(\"Random Forest Classifier Accuracy:\", rf_accuracy)\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# Logistic Regression (Logit)\n",
    "\n",
    "logit_classifier = LogisticRegression(\n",
    "    C=1.0,  # You can adjust the regularization strength by changing C\n",
    "    penalty='l2',  # Choose 'l1' or 'l2' for regularization type\n",
    "    solver='lbfgs',  # Choose the solver algorithm\n",
    "    max_iter=100,\n",
    "    fit_intercept=True,\n",
    "    multi_class='ovr'  # Choose 'ovr' or 'multinomial' for multiclass problems\n",
    ")\n",
    "\n",
    "logit_classifier.fit(X_train, y_train)\n",
    "logit_pred = logit_classifier.predict(X_test)\n",
    "logit_accuracy = accuracy_score(y_test, logit_pred)\n",
    "print(\"Logistic Regression Accuracy:\", logit_accuracy)\n",
    "print(classification_report(y_test, logit_pred))\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Create an XGBoost classifier with custom hyperparameters\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    n_estimators=100,        # Number of boosting rounds (trees)\n",
    "    max_depth=10,             # Maximum depth of trees\n",
    "    learning_rate=0.1,       # Learning rate (eta)\n",
    "    reg_alpha=0.1,           # L1 regularization\n",
    "    reg_lambda=0.1,          # L2 regularization\n",
    "    random_state=42          # Set a random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Train the model and make predictions\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "xgb_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "#xgb_classifier = XGBClassifier()\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "xgb_pred = xgb_classifier.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "print(\"XGBoost Classifier Accuracy:\", xgb_accuracy)\n",
    "print(classification_report(y_test, xgb_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Layer Perceptron (MLP) Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create an MLPClassifier with custom hyperparameters\n",
    "mlp_classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 10,5),\n",
    "    activation='logistic',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=1000,\n",
    "    alpha=0.1,  # Adjust the alpha value to control the strength of L2 regularization\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model and make predictions\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "mlp_pred = mlp_classifier.predict(X_test)\n",
    "mlp_accuracy = accuracy_score(y_test, mlp_pred)\n",
    "print(\"MLP Neural Network Accuracy:\", mlp_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, mlp_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4019a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, mlp_pred)\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['No Default', 'Default'], \n",
    "            yticklabels=['No Default', 'Default'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('MLP Confusion Matrix ')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea908443",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X1.columns\n",
    "print(col_names)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have X as a NumPy array and col_names as a list of column names\n",
    "\n",
    "# Create a DataFrame from X with column names\n",
    "X_df = pd.DataFrame(X, columns=col_names)\n",
    "\n",
    "# Assuming you have calculated avg_importance\n",
    "input_layer_weights = mlp_classifier.coefs_[0]\n",
    "\n",
    "# Compute the average importance across all neurons in the input layer\n",
    "avg_importance = np.mean(input_layer_weights, axis=1)\n",
    "# Create a bar chart for variable importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(avg_importance)), avg_importance)\n",
    "plt.xticks(range(len(col_names)), col_names, rotation=90)  # Set the number of ticks to match the number of labels\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Average Importance')\n",
    "plt.title('Input Weights for MLP Classifier')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d25fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef00dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming xgb_classifier is already trained\n",
    "# Extract feature importances\n",
    "importance_scores = xgb_classifier.feature_importances_\n",
    "\n",
    "# Assuming you have the original DataFrame with column names as X_df\n",
    "feature_names = X1.columns\n",
    "\n",
    "# Create a custom feature importance plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(feature_names)), importance_scores, align='center')\n",
    "plt.xticks(range(len(feature_names)), feature_names, rotation=90)  # Set the feature names as x-axis labels\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Feature Importance')\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9946da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_mat = confusion_matrix(y_test, xgb_pred)\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['No Default', 'Default'], yticklabels=['No Default', 'Default'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for XGBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9741bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "result = permutation_importance(mlp_classifier, X, y, n_repeats=100, random_state=0)\n",
    "importance_scores = result.importances_mean\n",
    "print(importance_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa213933",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613adb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(feature_names)), importance_scores, align='center')\n",
    "plt.xticks(range(len(feature_names)), feature_names, rotation=90)  # Set the feature names as x-axis labels\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Feature Importance')\n",
    "plt.title('MLP Feature Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71717818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
